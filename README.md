# HW5_2200357818_DogaDeryaBucan

# SVM  Linear vs Nonlinear Classification

This project is a hands-on exploration of **Support Vector Machines (SVMs)** using toy data that is **not linearly separable**. It demonstrates the **limitations of linear SVMs** and how **non-linear kernels (RBF)** solve complex classification problems.

## Objectives

1. Generate non-linearly separable 2D data
2. Fit and evaluate a **Linear SVM**
3. Fit and visualize a **Non-linear SVM** with **RBF kernel**
4. Visualize decision surfaces in **3D and 2D**
5. Compare classifier performance and interpret results


##  Key Concepts

- **Support Vectors**: Critical boundary points in SVM
- **Margin**: The gap SVM tries to maximize between classes
- **Kernel Trick**: Projects data to higher-dimensional space
- **RBF Kernel**: Allows nonlinear separation

## Technologies Used

- Python 3
- `numpy`
- `matplotlib`
- `scikit-learn`
- `mpl_toolkits` (for 3D plots)

## File Structure

```text
.
├── svm_experiment.ipynb         # Jupyter notebook with Python code, SVM implementation, and visualizations
├── README.md                    # Project overview, task explanations, and theoretical insights
└── requirements.txt             # List of Python libraries required to run the notebook (e.g., numpy, matplotlib, scikit-learn)
```

git clone https://github.com/DogaDeryaBucan/HW5_2200357818_DogaDeryaBucan.git

cd HW5_2200357818_DogaDeryaBucan




